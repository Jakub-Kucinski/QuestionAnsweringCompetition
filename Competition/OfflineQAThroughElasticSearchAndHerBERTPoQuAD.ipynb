{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f907e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from elasticsearch.helpers import streaming_bulk\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, AutoModel\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial import distance\n",
    "import torch\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62f505",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60375a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/task2_questions_with_answers.tsv', 'r', encoding='UTF-8') as f:\n",
    "    question_answers = []\n",
    "    for line in f:\n",
    "        splitted = line.strip().split(\"\\t\")\n",
    "        question_answers.append((splitted[0], splitted[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "18b091c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [qa[0] for qa in question_answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc5f65",
   "metadata": {},
   "source": [
    "# Pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f88c5987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\anaconda3\\envs\\PytorchCPU\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1132: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "yes_no_model = AutoModelWithLMHead.from_pretrained('flax-community/papuGaPT2')\n",
    "yes_no_tokenizer = AutoTokenizer.from_pretrained('flax-community/papuGaPT2')\n",
    "# yes_no_tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-large-cased\")\n",
    "# yes_no_model = AutoModelWithLMHead.from_pretrained(\"allegro/herbert-large-cased\")\n",
    "_ = yes_no_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed53643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b265af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pipeline_herbert = pipeline(\n",
    "    \"question-answering\",\n",
    "    model='azwierzc/herbert-large-poquad', handle_impossible_answer=True,\n",
    "    tokenizer='azwierzc/herbert-large-poquad'\n",
    ")\n",
    "\n",
    "def get_answer_herbert(context, question):\n",
    "    return qa_pipeline_herbert({\n",
    "        'context': context,\n",
    "        'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e545513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1c395371154242b1e7d5b637fc949a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/407 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbe85dc79fa47a0a31624150965e085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e57ddb016be48f799b16e630537379a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69b15bd81bb4bbca09e7f01e4a8245f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690d6643a7044d8d958f3b18f2de2405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/802 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c876d3a4944441069edb1226fda5b945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # PLT5 Large is about 3x slower than PLT5 Base\n",
    "# plt5_tokenizer = AutoTokenizer.from_pretrained(\"azwierzc/plt5-large-poquad\")\n",
    "# plt5_model = T5ForConditionalGeneration.from_pretrained(\"azwierzc/plt5-large-poquad\")\n",
    "# _ = plt5_model.eval()\n",
    "plt5_tokenizer = AutoTokenizer.from_pretrained(\"azwierzc/plt5-base-poquad\")\n",
    "plt5_model = T5ForConditionalGeneration.from_pretrained(\"azwierzc/plt5-base-poquad\")\n",
    "_ = plt5_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7a6b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_plt5(context, question):\n",
    "    query = plt5_tokenizer(f\"question: {question}, context: {context}\", \n",
    "                           max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "    output = plt5_model.generate(**query, max_new_tokens=8, num_beams=5, return_dict_in_generate=True, output_scores=True)\n",
    "    decoded_output = plt5_tokenizer.decode(output.sequences[0], skip_special_tokens=True)\n",
    "    score = np.exp(output.sequences_scores.numpy()[0])\n",
    "    return {'score': score, 'answer': decoded_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ee40b",
   "metadata": {},
   "source": [
    "# Connect to elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb961616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Password for the 'elastic' user generated by Elasticsearch\n",
    "ELASTIC_PASSWORD = YOUR_ELASTICSEARCH_PASSWORD\n",
    "# es_path = \"~/Documents/UWr/Chatbots/elasticsearch-8.4.3/\"\n",
    "es_path = \"C:/Users/jakub/elasticsearch-8.5.3-windows-x86_64/elasticsearch-8.5.3/\"\n",
    "\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    \"https://localhost:9200\",\n",
    "    ca_certs=es_path+\"config/certs/http_ca.crt\",\n",
    "    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b715b014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if you can connect to ES (bool)\n",
    "client.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e81d04",
   "metadata": {},
   "source": [
    "# Index documents from wikipedia paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f87869",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = \"../Data/fp_wiki.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d37483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actions():\n",
    "    with open(DATASET_FILE, \"r\", encoding=\"UTF-8\") as file:\n",
    "        # Read the first line of the file\n",
    "        title_line = file.readline()\n",
    "        # Create a variable to store the ID of the next document\n",
    "        next_id = 0\n",
    "        # Keep reading lines until the end of the file is reached\n",
    "        while title_line:\n",
    "            # Check if the line starts with \"Title: \"\n",
    "            if title_line.startswith(\"TITLE: \"):\n",
    "                # Get the title by stripping the \"Title: \" prefix and the newline character at the end\n",
    "                title = title_line.lstrip(\"TITLE:\").strip()\n",
    "                # Read the second line of the file, which should be the title again\n",
    "                title_line = file.readline().strip()\n",
    "                # Save title for later usage\n",
    "                title = title_line\n",
    "                # Create a list to store the lines of the article\n",
    "                article_lines = []\n",
    "                # Read the next line, which should be the start of the article\n",
    "                article_line = file.readline()\n",
    "                # Keep reading lines until an empty line is reached\n",
    "                while article_line.strip():\n",
    "                    # Add the line to the list of article lines\n",
    "                    article_lines.append(article_line)\n",
    "                    # Read the next line\n",
    "                    article_line = file.readline()\n",
    "                # Join the lines of the article with newline characters to create the article\n",
    "                article = \"\\n\".join(article_lines) if article_lines else \"\"\n",
    "                # Create a dictionary for the document\n",
    "                document = {\"_id\": next_id, \"title\": title, \"article\": article}\n",
    "                # Yield new document\n",
    "                yield document\n",
    "                # Increment the ID for the next document\n",
    "                next_id += 1\n",
    "                # Read the next line, which should be the start of the next document\n",
    "                title_line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9c5eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"offline_competition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84f2ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"lang_pl_morfologik\": { \n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"morfologik_stem\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"long\"},\n",
    "            \"article\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"lang_pl_morfologik\"\n",
    "            },\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"lang_pl_morfologik\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff863ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'offline_competition'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.options(ignore_status=[400,404]).indices.delete(index=index_name)\n",
    "\n",
    "client.indices.create(\n",
    "    index=index_name,\n",
    "    settings=configurations[\"settings\"],\n",
    "    mappings=configurations[\"mappings\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd90bde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████▉| 1207501/1209001 [04:36<00:00, 4717.47docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 1208362/1209001 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████▉| 1208362/1209001 [04:50<00:00, 4717.47docs/s]"
     ]
    }
   ],
   "source": [
    "print(\"Indexing documents...\")\n",
    "number_of_docs=1209001\n",
    "progress = tqdm(unit=\"docs\", total=number_of_docs)\n",
    "successes = 0\n",
    "for ok, action in streaming_bulk(\n",
    "    client=client, index=index_name, actions=generate_actions(),\n",
    "):\n",
    "    progress.update(1)\n",
    "    successes += ok\n",
    "print(\"Indexed %d/%d documents\" % (successes, number_of_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54444219",
   "metadata": {},
   "source": [
    "# Answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f2af0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(question, index_name=\"offline_competition\", k=3):\n",
    "    resp = client.search(index=index_name, \n",
    "                     query={'match': {\n",
    "                         \"article\": question\n",
    "                     }})\n",
    "    best_documents = list(sorted(resp['hits']['hits'], key=lambda k: k['_score'], reverse=True))\n",
    "    context = \"\"\n",
    "    for document in best_documents[:k]:\n",
    "        if document['_source']['title'].lower() not in document['_source']['article'].lower():\n",
    "            context += document['_source']['title'] + \" . \"\n",
    "        context += document['_source']['article'] + \"\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c82da",
   "metadata": {},
   "source": [
    "## Herbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0990f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27a44ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3500/3500 [3:04:14<00:00,  3.16s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(f'HerbertAnswers/offline_competition_k_{k}.txt', 'a', encoding='UTF-8') as f:\n",
    "    with open(f'HerbertAnswers/offline_competition_k_{k}_with_confidence.txt', 'a', encoding='UTF-8') as f_confidence:\n",
    "        for question, _ in tqdm(question_answers):\n",
    "            context = retriever(question, index_name=\"offline_competition\", k=k)\n",
    "            result = get_answer_herbert(context, question)\n",
    "            predicted_answer = result['answer'].replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n",
    "            confidence = result['score'] if predicted_answer != \"\" else 0.0\n",
    "            f.write(predicted_answer + \"\\n\")\n",
    "            f_confidence.write(f\"{predicted_answer}\\t{confidence}\\n\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f77770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAnswers/offline_competition_k_{k}.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3df89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    for _, answers in question_answers:\n",
    "        f.write(\"\\t\".join(answers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02a409fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.21114285714285713\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a4ae3",
   "metadata": {},
   "source": [
    "## PLT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "528c9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4a15677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3500/3500 [2:06:52<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(f'PLT5BaseAnswers/offline_competition_k_{k}.txt', 'a', encoding='UTF-8') as f:\n",
    "    with open(f'PLT5BaseAnswers/offline_competition_k_{k}_with_confidence.txt', 'a', encoding='UTF-8') as f_confidence:\n",
    "        for question, _ in tqdm(question_answers):\n",
    "            context = retriever(question, index_name=\"offline_competition\", k=k)\n",
    "            result = get_answer_plt5(context, question)\n",
    "            predicted_answer = result['answer'].replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n",
    "            confidence = result['score'] if predicted_answer != \"\" else 0.0\n",
    "            f.write(predicted_answer + \"\\n\")\n",
    "            f_confidence.write(f\"{predicted_answer}\\t{confidence}\\n\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b7dd185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'PLT5BaseAnswers/offline_competition_k_{k}.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c717f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestA_Offline.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "64d02cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    for _, answers in question_answers:\n",
    "        f.write(\"\\t\".join(answers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d2b76e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.3485714285714286\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12e755",
   "metadata": {},
   "source": [
    "# Join Herbert and PLT5 answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6b7e4",
   "metadata": {},
   "source": [
    "## Herbert > PLT5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f27e0d3",
   "metadata": {},
   "source": [
    "Worse than pure PLT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fafb5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'PLT5BaseAnswers/offline_competition_k_5.txt', 'r', encoding='UTF-8') as f_plt5:\n",
    "    with open(f'HerbertAnswers/offline_competition_k_3.txt', 'r', encoding='UTF-8') as f_herbert:\n",
    "        with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_PLT5_if_no_Herbert_answer.txt', 'a',\n",
    "                  encoding='UTF-8') as f_combined:\n",
    "            for herbert_answer, plt5_answer in zip(f_herbert, f_plt5):\n",
    "                herbert_answer = herbert_answer.strip()\n",
    "                plt5_answer = plt5_answer.strip()\n",
    "                if herbert_answer != \"\":\n",
    "                    f_combined.write(herbert_answer + \"\\n\")\n",
    "                else:\n",
    "                    f_combined.write(plt5_answer + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6a230234",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_PLT5_if_no_Herbert_answer.txt', 'r',\n",
    "          encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6d05774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    for _, answers in question_answers:\n",
    "        f.write(\"\\t\".join(answers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cddb6cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.3048571428571429\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b444ec9",
   "metadata": {},
   "source": [
    "## PLT5 > Herbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2dd304",
   "metadata": {},
   "source": [
    "Better than pure PLT5 and Herbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d0a2cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'PLT5BaseAnswers/offline_competition_k_5.txt', 'r', encoding='UTF-8') as f_plt5:\n",
    "    with open(f'HerbertAnswers/offline_competition_k_3.txt', 'r', encoding='UTF-8') as f_herbert:\n",
    "        with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer.txt', 'a',\n",
    "                  encoding='UTF-8') as f_combined:\n",
    "            for herbert_answer, plt5_answer in zip(f_herbert, f_plt5):\n",
    "                herbert_answer = herbert_answer.strip()\n",
    "                plt5_answer = plt5_answer.strip()\n",
    "                if plt5_answer != \"\":\n",
    "                    f_combined.write(plt5_answer + \"\\n\")\n",
    "                else:\n",
    "                    f_combined.write(herbert_answer + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c12fc",
   "metadata": {},
   "source": [
    "#### Test A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e2b0de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer.txt', 'r',\n",
    "          encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c64ba194",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestA_Offline.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5d5970d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    for _, answers in question_answers:\n",
    "        f.write(\"\\t\".join(answers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cbb55177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.3534285714285714\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bba43",
   "metadata": {},
   "source": [
    "#### Test A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c04e958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer.txt', 'r',\n",
    "          encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            if index % 5 == 0:\n",
    "                f_answers.write(line)\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "40072e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestAprime_Offline.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "36cf58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    index = 0\n",
    "    for _, answers in question_answers:\n",
    "        if index % 5 == 0:\n",
    "            f.write(\"\\t\".join(answers) + \"\\n\")\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5665d302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.3585714285714286\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446f18c",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e9386",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fee9ff",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114cc75",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec437e7f",
   "metadata": {},
   "source": [
    "#  Modifications below didn't improve score of combined PLT5 and Herbert  answers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20596820",
   "metadata": {},
   "source": [
    "## Handle special type of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9c4cbbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [question for question, _ in question_answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a1358",
   "metadata": {},
   "source": [
    "## Yes/No questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "98aac1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_yes_no_question(question):\n",
    "    return question[:4] == \"Czy \" and \" czy \" not in question[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "db46afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_prob(text):\n",
    "    input_ids = torch.tensor(yes_no_tokenizer.encode(text)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = yes_no_model(input_ids, labels=input_ids)\n",
    "    loss, logits = outputs[:2]\n",
    "    sentence_prob = loss.item()\n",
    "    return sentence_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e6b91d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_yes_no_question(question):\n",
    "    yes_sentence_prob = get_sentence_prob(question + \" Tak\")\n",
    "    no_sentence_prob = get_sentence_prob(question + \" Nie\")\n",
    "    return \"tak\" if yes_sentence_prob > no_sentence_prob else \"nie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "df1b60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_yes_no_answer(answer):\n",
    "    answer = answer.strip().lower()\n",
    "    return answer == \"tak\" or answer == \"nie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d931f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer.txt', 'r',\n",
    "          encoding='UTF-8') as f:\n",
    "    with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer_yes_no.txt', 'w',\n",
    "              encoding='UTF-8') as f_answers:\n",
    "        raw_answers = []\n",
    "        for line in f:\n",
    "            raw_answers.append(line.strip())\n",
    "        for question, raw_answer in zip(questions, raw_answers):\n",
    "            if is_yes_no_question(question) and not is_yes_no_answer(raw_answer):\n",
    "                f_answers.write(answer_yes_no_question(question) + \"\\n\")\n",
    "            else:\n",
    "                f_answers.write(raw_answer + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f21c4",
   "metadata": {},
   "source": [
    "#### Test A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "61fc5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer_yes_no.txt', 'r',\n",
    "          encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee4b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestA_Offline.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2f341c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    for _, answers in question_answers:\n",
    "        f.write(\"\\t\".join(answers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "82554b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.3534285714285714\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00a715",
   "metadata": {},
   "source": [
    "#### Test A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1d0b8509",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer_yes_no.txt', 'r',\n",
    "          encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            if index % 5 == 0:\n",
    "                f_answers.write(line)\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "27f0e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestAprime_Offline.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c27656df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    index = 0\n",
    "    for _, answers in question_answers:\n",
    "        if index % 5 == 0:\n",
    "            f.write(\"\\t\".join(answers) + \"\\n\")\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0e0bf011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.3585714285714286\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b4449",
   "metadata": {},
   "source": [
    "## Optional questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1732dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_optional_question(question):\n",
    "    to_pointer = question.find(\" to \")\n",
    "    if to_pointer == -1:\n",
    "        return False\n",
    "    czy_part = question[to_pointer:]\n",
    "    czy_pointer = czy_part.find(\" czy \")\n",
    "    return czy_pointer != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c06bb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_and_options(question):\n",
    "    if (dot_pointer := question.find(\".\")) != -1:\n",
    "        question = question[dot_pointer:]\n",
    "    if question[-1] == \"?\":\n",
    "        question = question[:-1]\n",
    "    if question.lower()[:3] == 'czy':\n",
    "        question = question[3:].strip()\n",
    "    term, options = question.split(' to ')\n",
    "    options = options.split(' czy ')\n",
    "    first_options = options[0]\n",
    "    first_options = first_options.split(\",\")\n",
    "    first_options.extend(options[1:])\n",
    "    return term.strip(), [opt.strip() for opt in first_options if opt.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "343d9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_optional_question(question):\n",
    "    term, options = get_term_and_options(question)\n",
    "    options_embeddings = embedding_model.encode(options)\n",
    "    term_embedding = embedding_model.encode(term)\n",
    "    similarity = np.array([distance.cosine(term_embedding, emb) for emb in options_embeddings])\n",
    "    return options[np.argmin(similarity)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "03353bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer_yes_no.txt', 'r',\n",
    "          encoding='UTF-8') as f:\n",
    "    with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer_yes_no_optional.txt', 'w',\n",
    "              encoding='UTF-8') as f_answers:\n",
    "        raw_answers = []\n",
    "        for line in f:\n",
    "            raw_answers.append(line.strip())\n",
    "        for question, raw_answer in zip(questions, raw_answers):\n",
    "            if not is_yes_no_question(question) and is_optional_question(question):\n",
    "                f_answers.write(answer_optional_question(question) + \"\\n\")\n",
    "            else:\n",
    "                f_answers.write(raw_answer + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b325e77",
   "metadata": {},
   "source": [
    "#### Test A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dee04c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer_yes_no_optional.txt', 'r',\n",
    "          encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0b9c41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestA_Offline.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "74e2c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    for _, answers in question_answers:\n",
    "        f.write(\"\\t\".join(answers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c312b0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.35\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ea75d",
   "metadata": {},
   "source": [
    "#### Test A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cd3e05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'HerbertAndPLT5Answers/offline_competition_answer_with_Herbert_if_no_PLT5_answer_yes_no_optional.txt', 'r',\n",
    "          encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            if index % 5 == 0:\n",
    "                f_answers.write(line)\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "814fb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestAprime_Offline.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "41ca4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    index = 0\n",
    "    for _, answers in question_answers:\n",
    "        if index % 5 == 0:\n",
    "            f.write(\"\\t\".join(answers) + \"\\n\")\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b24e2258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.3557142857142857\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63406fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
