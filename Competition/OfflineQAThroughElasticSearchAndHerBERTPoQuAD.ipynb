{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f907e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from elasticsearch.helpers import streaming_bulk\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62f505",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60375a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/task2_questions_with_answers.tsv', 'r', encoding='UTF-8') as f:\n",
    "    question_answers = []\n",
    "    for line in f:\n",
    "        splitted = line.strip().split(\"\\t\")\n",
    "        question_answers.append((splitted[0], splitted[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef0959b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Proszę rozwinąć skrót powstałego w 1918 roku urzędu GUS.',\n",
       " 'Dokończ przysłowie: „pierwsze koty za...”',\n",
       " 'Proszę podać polską nazwę organizacji gospodarczej o skrócie EFTA.',\n",
       " 'Podaj wzór chemiczny lodu.',\n",
       " 'Wskaż przyimek w zdaniu „Idę do szkoły”.',\n",
       " 'Rozwiń skrót NFZ.',\n",
       " 'Proszę dokończyć przysłowie: „nosił wilk razy kilka...”',\n",
       " 'Dokończ: „siła złego na...”',\n",
       " 'Proszę rozwinąć skrót IPN.',\n",
       " 'Dokończ przysłowie: „Kazał pan...”',\n",
       " 'Dokończ przysłowie: wszędzie dobrze, ale...',\n",
       " 'Proszę podać imię i nazwisko aktora odtwarzającego rolę Lucjana Mostowiaka.',\n",
       " 'Jak nazywa się okres sprawowania funkcji przez papieża? Słowo pochodzi z łaciny.',\n",
       " 'Jak nazywa się nadzienie do pierogów albo naleśników? Słowo pochodzi z języka francuskiego.',\n",
       " 'Rozwiń skrót „CBŚ”.',\n",
       " 'Proszę podać dokładną datę radzieckiej agresji na Polskę w czasie II wojny światowej.',\n",
       " 'Rozszyfruj skrót GOPR.',\n",
       " 'Proszę podać nazwę jednej z najwyższych zapór wodnych świata na rzece Kolorado, niedaleko Las Vegas.',\n",
       " 'Z którego dramatu pochodzi cytat: „Chłop potęgą jest i basta?”',\n",
       " 'Jak nazywa się dział piśmiennictwa chrześcijańskiego obejmujący żywoty świętych i legendy o nich? Nazwa pochodzi z greki.',\n",
       " 'Proszę podać imiona Maradony.',\n",
       " 'Laudację można wybić czy wygłosić',\n",
       " 'Proszę wymienić pierwszy stopień odmiany przymiotnika.',\n",
       " 'Proszę podać datę zdobycia Bastylii.',\n",
       " 'Proszę podać oba imiona pana Zagłoby.',\n",
       " 'Pieter Bruegel Starszy miał dwóch synów. Proszę podać imię jednego z nich.',\n",
       " 'Proszę dokończyć zdanie Ignacego Krasickiego: „Prawdziwa cnota...”',\n",
       " 'Jak dawniej nazywał się żołnierz pełniący stałą służbę przy oficerze? Słowo pochodzi z francuskiego.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[question for question, answers in question_answers if \"?\" != question[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc5f65",
   "metadata": {},
   "source": [
    "# Pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f88c5987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\anaconda3\\envs\\PytorchCPU\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1132: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes_no_model = AutoModelWithLMHead.from_pretrained('flax-community/papuGaPT2')\n",
    "yes_no_tokenizer = AutoTokenizer.from_pretrained('flax-community/papuGaPT2')\n",
    "# yes_no_tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-large-cased\")\n",
    "# yes_no_model = AutoModelWithLMHead.from_pretrained(\"allegro/herbert-large-cased\")\n",
    "yes_no_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b265af11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dcb5efe36b4db2a7657cb61ff68799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/884 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\anaconda3\\envs\\PytorchCPU\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jakub\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abd316fbfb649e58d28b62e23f670c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4939bbd967406387f7a63d3f38e230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/559 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467e774126be4c3b851acfcf0e156285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/907k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699b9a00ccbd4e5bb313578724b598a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/556k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c84f0b20a024ec1905c469968dc90fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3225217bb3a3405f82901d960d456d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/144 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model='azwierzc/herbert-large-poquad', handle_impossible_answer=True,\n",
    "    tokenizer='azwierzc/herbert-large-poquad'\n",
    ")\n",
    "\n",
    "def get_answer(context, question):\n",
    "    return qa_pipeline({\n",
    "        'context': context,\n",
    "        'question': question})['answer'].replace(\"\\n\", \" \").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ee40b",
   "metadata": {},
   "source": [
    "# Connect to elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb961616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'SZCZUPAK', 'cluster_name': 'elasticsearch', 'cluster_uuid': 'jTU4rQqTShilMYzr6mVpvw', 'version': {'number': '8.5.3', 'build_flavor': 'default', 'build_type': 'zip', 'build_hash': '4ed5ee9afac63de92ec98f404ccbed7d3ba9584e', 'build_date': '2022-12-05T18:22:22.226119656Z', 'build_snapshot': False, 'lucene_version': '9.4.2', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Password for the 'elastic' user generated by Elasticsearch\n",
    "ELASTIC_PASSWORD = FILL_IN_PASSWORD\n",
    "# es_path = \"~/Documents/UWr/Chatbots/elasticsearch-8.4.3/\"\n",
    "es_path = \"C:/Users/jakub/elasticsearch-8.5.3-windows-x86_64/elasticsearch-8.5.3/\"\n",
    "\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    \"https://localhost:9200\",\n",
    "    ca_certs=es_path+\"config/certs/http_ca.crt\",\n",
    "    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
    ")\n",
    "\n",
    "client.info()\n",
    "# Should return sth like {'name': 'instance-0000000000', 'cluster_name': ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b715b014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if you can connect to ES (bool)\n",
    "client.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e81d04",
   "metadata": {},
   "source": [
    "# Index documents from wikipedia paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f87869",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = \"../Data/fp_wiki.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d37483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actions():\n",
    "    with open(DATASET_FILE, \"r\", encoding=\"UTF-8\") as file:\n",
    "        # Read the first line of the file\n",
    "        title_line = file.readline()\n",
    "        # Create a variable to store the ID of the next document\n",
    "        next_id = 0\n",
    "        # Keep reading lines until the end of the file is reached\n",
    "        while title_line:\n",
    "            # Check if the line starts with \"Title: \"\n",
    "            if title_line.startswith(\"TITLE: \"):\n",
    "                # Get the title by stripping the \"Title: \" prefix and the newline character at the end\n",
    "                title = title_line.lstrip(\"TITLE:\").strip()\n",
    "                # Read the second line of the file, which should be the title again\n",
    "                title_line = file.readline().strip()\n",
    "                # Save title for later usage\n",
    "                title = title_line\n",
    "                # Create a list to store the lines of the article\n",
    "                article_lines = []\n",
    "                # Read the next line, which should be the start of the article\n",
    "                article_line = file.readline()\n",
    "                # Keep reading lines until an empty line is reached\n",
    "                while article_line.strip():\n",
    "                    # Add the line to the list of article lines\n",
    "                    article_lines.append(article_line)\n",
    "                    # Read the next line\n",
    "                    article_line = file.readline()\n",
    "                # Join the lines of the article with newline characters to create the article\n",
    "                article = \"\\n\".join(article_lines) if article_lines else \"\"\n",
    "                # Create a dictionary for the document\n",
    "                document = {\"_id\": next_id, \"title\": title, \"article\": article}\n",
    "                # Yield new document\n",
    "                yield document\n",
    "                # Increment the ID for the next document\n",
    "                next_id += 1\n",
    "                # Read the next line, which should be the start of the next document\n",
    "                title_line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9c5eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"offline_competition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84f2ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"lang_pl_morfologik\": { \n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"morfologik_stem\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"long\"},\n",
    "            \"article\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"lang_pl_morfologik\"\n",
    "            },\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"lang_pl_morfologik\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff863ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'offline_competition'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.options(ignore_status=[400,404]).indices.delete(index=index_name)\n",
    "\n",
    "client.indices.create(\n",
    "    index=index_name,\n",
    "    settings=configurations[\"settings\"],\n",
    "    mappings=configurations[\"mappings\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd90bde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████▉| 1207501/1209001 [04:36<00:00, 4717.47docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 1208362/1209001 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████▉| 1208362/1209001 [04:50<00:00, 4717.47docs/s]"
     ]
    }
   ],
   "source": [
    "print(\"Indexing documents...\")\n",
    "number_of_docs=1209001\n",
    "progress = tqdm(unit=\"docs\", total=number_of_docs)\n",
    "successes = 0\n",
    "for ok, action in streaming_bulk(\n",
    "    client=client, index=index_name, actions=generate_actions(),\n",
    "):\n",
    "    progress.update(1)\n",
    "    successes += ok\n",
    "print(\"Indexed %d/%d documents\" % (successes, number_of_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54444219",
   "metadata": {},
   "source": [
    "# Answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f2af0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(question, index_name=\"offline_competition\", k=3):\n",
    "    resp = client.search(index=index_name, \n",
    "                     query={'match': {\n",
    "                         \"article\": question\n",
    "                     }})\n",
    "    best_documents = list(sorted(resp['hits']['hits'], key=lambda k: k['_score'], reverse=True))\n",
    "    context = \"\"\n",
    "    for document in best_documents[:k]:\n",
    "        if document['_source']['title'].lower() not in document['_source']['article'].lower():\n",
    "            context += document['_source']['title'] + \" . \"\n",
    "        context += document['_source']['article'] + \"\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27a44ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3500/3500 [3:04:14<00:00,  3.16s/it]\n"
     ]
    }
   ],
   "source": [
    "with open('HerbertAnswers/offline_competition_k_3.txt', 'a', encoding='UTF-8') as f:\n",
    "    for question, _ in tqdm(question_answers):\n",
    "        context = retriever(question, index_name=\"offline_competition\", k=3)\n",
    "        predicted_answer = get_answer(context, question)\n",
    "        f.write(predicted_answer.replace(\"\\n\", \" \").strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f77770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('HerbertAnswers/offline_competition_k_3.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3df89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    for _, answers in question_answers:\n",
    "        f.write(\"\\t\".join(answers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02a409fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.21114285714285713\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4deff0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.21114285714285713\n"
     ]
    }
   ],
   "source": [
    "import editdistance\n",
    "import sys\n",
    "\n",
    "rn = ['ii', 'iii', 'iv', 'v', 'vi', 'vii', 'viii', 'ix', 'x', 'xi', 'xii', 'xiii',\n",
    "                 'xiv', 'xv', 'xvi', 'xvii', 'xviii', 'xix', 'xx', 'xxi', 'xxii']\n",
    "\n",
    "rome_numbers = dict(zip(rn, range(2, 23)))\n",
    "\n",
    "def numbers_from(s):\n",
    "    res = set()\n",
    "    for w in s.split():\n",
    "        w = w.lower()\n",
    "        if w.isdecimal():\n",
    "            res.add(w)\n",
    "        if w in rome_numbers:\n",
    "            res.add(rome_numbers[w])\n",
    "    return res                 \n",
    "                 \n",
    "                 \n",
    "def is_number(s):\n",
    "    return lower(s) in rome_numbers or s.isdecimal()\n",
    "                     \n",
    "def scaled_editdist(ans, cor):\n",
    "    ans = ans.lower()\n",
    "    cor = cor.lower()\n",
    "    \n",
    "    return editdistance.eval(ans, cor) / len(cor)\n",
    "    \n",
    "def single_match(a, c):\n",
    "    numbers_c = numbers_from(c)\n",
    "    numbers_a = numbers_from(a)\n",
    "        \n",
    "    return numbers_a == numbers_c and scaled_editdist(a, c) < 0.5\n",
    "        \n",
    "def match(ans, cor):\n",
    "    return any(single_match(ans, c) for c in cor)\n",
    "        \n",
    "found_answers = []\n",
    "correct_answers = []\n",
    "\n",
    "for x in open('correct_answers.txt', encoding=\"UTF-8\"):\n",
    "    x = x.strip()\n",
    "    correct_answers.append(x.lower().split('\\t'))\n",
    "    \n",
    "for x in open('found_answers.txt', encoding=\"UTF-8\"):    \n",
    "    x = x.strip()\n",
    "    found_answers.append(x.lower())\n",
    "    \n",
    "N = len(correct_answers)\n",
    "score = 0.0\n",
    "\n",
    "for ans, cor in zip(found_answers, correct_answers):    \n",
    "    if match(ans, cor):\n",
    "        score += 1\n",
    "        \n",
    "print ('TOTAL SCORE:', score / len(correct_answers))        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20596820",
   "metadata": {},
   "source": [
    "# Handle special type of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c4cbbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [question for question, _ in question_answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a1358",
   "metadata": {},
   "source": [
    "## Yes/No questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "98aac1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_yes_no_question(question):\n",
    "    return question[:4] == \"Czy \" and \" czy \" not in question[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "db46afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_prob(text):\n",
    "    input_ids = torch.tensor(yes_no_tokenizer.encode(text)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = yes_no_model(input_ids, labels=input_ids)\n",
    "    loss, logits = outputs[:2]\n",
    "    sentence_prob = loss.item()\n",
    "    return sentence_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e6b91d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_yes_no_question(question):\n",
    "    yes_sentence_prob = get_sentence_prob(question + \" Tak\")\n",
    "    no_sentence_prob = get_sentence_prob(question + \" Nie\")\n",
    "    return \"tak\" if yes_sentence_prob > no_sentence_prob else \"nie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d931f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('HerbertAnswers/offline_competition_k_3.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('HerbertAnswers/offline_competition_k_3_yes_no.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        raw_answers = []\n",
    "        for line in f:\n",
    "            raw_answers.append(line.strip())\n",
    "        for question, raw_answer in zip(questions, raw_answers):\n",
    "            if is_yes_no_question(question):\n",
    "                f_answers.write(answer_yes_no_question(question) + \"\\n\")\n",
    "            else:\n",
    "                f_answers.write(raw_answer + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f21c4",
   "metadata": {},
   "source": [
    "### Test A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61fc5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('HerbertAnswers/offline_competition_k_3_yes_no.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee4b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestA_Offline.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f341c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    for _, answers in question_answers:\n",
    "        f.write(\"\\t\".join(answers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82554b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.2642857142857143\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00a715",
   "metadata": {},
   "source": [
    "### Test A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c04e958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('HerbertAnswers/offline_competition_k_3_yes_no.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        k = 0\n",
    "        for line in f:\n",
    "            if k % 5 == 0:\n",
    "                f_answers.write(line)\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40072e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestAprime_Offline.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36cf58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    k = 0\n",
    "    for _, answers in question_answers:\n",
    "        if k % 5 == 0:\n",
    "            f.write(\"\\t\".join(answers) + \"\\n\")\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5665d302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.2814285714285714\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b4449",
   "metadata": {},
   "source": [
    "## Optional questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922940a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63406fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
