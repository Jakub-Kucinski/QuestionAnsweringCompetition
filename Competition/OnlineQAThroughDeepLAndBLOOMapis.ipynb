{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e126aa",
   "metadata": {},
   "source": [
    "# Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab1121a",
   "metadata": {},
   "source": [
    "Translations of answers:\n",
    "- only answers\n",
    "- question + answer, then remove question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5154b631",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb1ed6d",
   "metadata": {},
   "source": [
    "- Add DeepL API key\n",
    "- Translate questions to english through DeepL API, save them on disk\n",
    "- Get answers through getting closes supporting questions and asking BLOOM API, postprocess and save on disk\n",
    "- Translate answers to polish\n",
    "- Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f66b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ijson\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from transformers import pipeline, set_seed\n",
    "from random import sample\n",
    "import requests\n",
    "import time\n",
    "from json import JSONDecodeError\n",
    "import editdistance\n",
    "import sys\n",
    "import random\n",
    "import deepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe5adb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character usage: 362655 of 500000\n"
     ]
    }
   ],
   "source": [
    "auth_key = YOUR_KEY  # Replace with your key\n",
    "translator = deepl.Translator(auth_key)\n",
    "usage = translator.get_usage()\n",
    "if usage.any_limit_reached:\n",
    "    print('Translation limit reached.')\n",
    "if usage.character.valid:\n",
    "    print(f\"Character usage: {usage.character.count} of {usage.character.limit}\")\n",
    "if usage.document.valid:\n",
    "    print(f\"Document usage: {usage.document.count} of {usage.document.limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bf22d",
   "metadata": {},
   "source": [
    "# Create translations with DeepL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06383066",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/task2_questions_with_answers.tsv', 'r', encoding='UTF-8') as f:\n",
    "    question_answers = []\n",
    "    for line in f:\n",
    "        splitted = line.strip().split(\"\\t\")\n",
    "        question_answers.append((splitted[0], splitted[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c8e6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/task2_questions_translated.txt', 'a', encoding='UTF-8') as f:\n",
    "    for question, _ in tqdm(question_answers):\n",
    "        result = translator.translate_text(question, target_lang=\"EN-US\", source_lang=\"PL\")\n",
    "        f.write(result.text.strip() + \"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94526153",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e2d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/triviaqa-unfiltered/unfiltered-web-dev.json', 'r', encoding='UTF-8') as f:\n",
    "    objects = ijson.items(f, \"Data.item\")\n",
    "    dataset1 = [(o[\"Question\"], o[\"Answer\"][\"Value\"]) for o in objects]\n",
    "    del objects\n",
    "\n",
    "with open('../Data/triviaqa-unfiltered/unfiltered-web-train.json', 'r', encoding='UTF-8') as f:\n",
    "    objects = ijson.items(f, \"Data.item\")\n",
    "    dataset2 = [(o[\"Question\"], o[\"Answer\"][\"Value\"]) for o in objects]\n",
    "    del objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e29aa674",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/task2_questions_with_answers.tsv', 'r', encoding='UTF-8') as f:\n",
    "    question_answers = []\n",
    "    for line in f:\n",
    "        splitted = line.strip().split(\"\\t\")\n",
    "        question_answers.append((splitted[0], splitted[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8006f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/task2_questions_translated.txt', 'r', encoding='UTF-8') as f:\n",
    "    question_eng = []\n",
    "    for line in f:\n",
    "        question_eng.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52242f",
   "metadata": {},
   "source": [
    "# Embed triviaqa questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2424bc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1370/1370 [1:02:30<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "# model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "questions = [q for q,a in dataset2]\n",
    "\n",
    "question_embeddings = []\n",
    "\n",
    "N = len(questions)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(N // batch_size + 1)):\n",
    "    batch = questions[i * batch_size : min((i+1) * batch_size, N)]\n",
    "    question_embeddings.extend(model.encode(batch))\n",
    "    \n",
    "question_embeddings = np.array(question_embeddings)\n",
    "# 1370/1370 [10:40<00:00,  2.14it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06ef4423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87622, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3efeca3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(n_neighbors=25)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(n_neighbors=25)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(n_neighbors=25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=25)\n",
    "neigh.fit(question_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3f496c",
   "metadata": {},
   "source": [
    "# Ask BLOOM with 25 supporting questions-answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e74ea449",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/bigscience/bloom\"\n",
    "API_TOKEN = YOUR_TOKEN\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba0d9a94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3500/3500 [8:16:02<00:00,  8.50s/it]\n"
     ]
    }
   ],
   "source": [
    "with open('BLOOMAnswers/question_and_answer_raw.txt', 'a', encoding='UTF-8') as f:\n",
    "    for question in tqdm(question_eng):\n",
    "        embedding = model.encode([question])\n",
    "        distances, indices = neigh.kneighbors(embedding, n_neighbors=25)\n",
    "\n",
    "        chosen = [dataset2[i] for i in indices[0]]\n",
    "\n",
    "        text = \"\"\n",
    "\n",
    "        for q, a in chosen:\n",
    "            support = \"Question: \" + q.strip() + \" Answer: \" + a.strip().capitalize() + \". \"\n",
    "            text += support\n",
    "        text += \"Question: \" + question.strip() + \" Answer:\"\n",
    "        \n",
    "        successful = False\n",
    "        \n",
    "        while not successful:\n",
    "            successful = True\n",
    "            try:\n",
    "                results = query({\n",
    "                    \"inputs\": text,\n",
    "                    \"parameters\": {\"max_new_tokens\": 4,\n",
    "                                  \"num_return_sequences\": 1,\n",
    "                                  \"do_sample\": False}\n",
    "                })\n",
    "                res = results[0]\n",
    "                predicted_answer = res['generated_text']\n",
    "                predicted_answer = predicted_answer.strip()\n",
    "                if predicted_answer[-8:] == \"Question\":\n",
    "                    predicted_answer = predicted_answer[:-8]\n",
    "                elif predicted_answer[-9:] == \"Question:\":\n",
    "                    predicted_answer = predicted_answer[:-9]\n",
    "                predicted_answer = predicted_answer.strip()\n",
    "                if predicted_answer[-1] == \".\":\n",
    "                    predicted_answer = predicted_answer[:-1]\n",
    "                predicted_answer = predicted_answer[predicted_answer.rfind(\"Question:\"):]\n",
    "            except JSONDecodeError:\n",
    "                predicted_answer = \"Question: \" + question.strip() + \" Answer: \"\n",
    "            except KeyError:\n",
    "                successful = False\n",
    "                time.sleep(15.0)\n",
    "        f.write(predicted_answer.replace(\"\\n\", \" \").strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f6bcda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_from_raw_question_answer(qa, translate_with_question=False):\n",
    "    if translate_with_question:\n",
    "        pass\n",
    "    else:\n",
    "        answer = qa[qa.rfind(\"Answer:\")+8:]\n",
    "        if answer.strip() == \"\":\n",
    "            return \"Yes\"\n",
    "        result = translator.translate_text(answer, target_lang=\"PL\", source_lang=\"EN\")\n",
    "        return result.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f305d840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3500it [09:16,  6.29it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('BLOOMAnswers/question_and_answer_raw.txt', 'r', encoding='UTF-8') as f_raw:\n",
    "    with open('BLOOMAnswers/predicted_answers_polish.txt', 'a', encoding='UTF-8') as f_translated:\n",
    "        for raw_line in tqdm(f_raw):\n",
    "            f_translated.write(get_answer_from_raw_question_answer(raw_line.strip()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f08c7d",
   "metadata": {},
   "source": [
    "# Test A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad790c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BLOOMAnswers/predicted_answers_polish.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d7e8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestA_Online.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a147a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    for _, answers in question_answers:\n",
    "        f.write(\"\\t\".join(answers) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b607157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.41828571428571426\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d2971",
   "metadata": {},
   "source": [
    "# Test A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c0ed747",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BLOOMAnswers/predicted_answers_polish.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('found_answers.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        k = 0\n",
    "        for line in f:\n",
    "            if k % 5 == 0:\n",
    "                f_answers.write(line)\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "703ce5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_answers.txt', 'r', encoding='UTF-8') as f:\n",
    "    with open('FinalAnswers/TestAprime_Online.txt', 'w', encoding='UTF-8') as f_answers:\n",
    "        for line in f:\n",
    "            f_answers.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "022603e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correct_answers.txt', 'w', encoding='UTF-8') as f:\n",
    "    k = 0\n",
    "    for _, answers in question_answers:\n",
    "        if k % 5 == 0:\n",
    "            f.write(\"\\t\".join(answers) + \"\\n\")\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6286dcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SCORE: 0.4257142857142857\n"
     ]
    }
   ],
   "source": [
    "!python advent_answer_check.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970da6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
